# MTR MCP Server - Complete Documentation

> **Last Updated:** October 21, 2025  
> **Version:** 3.0 (Full MCP Feature Set with Memory)

---

## ğŸ“‘ Table of Contents

1. [Overview](#-overview)
2. [Quick Start](#-quick-start)
3. [MCP Protocol Understanding](#-mcp-protocol-understanding)
4. [Server Features](#-server-features)
5. [LangGraph Integration](#-langgraph-integration)
6. [System Prompt Guide](#-system-prompt-guide)
7. [LangSmith Observability](#-langsmith-observability)
8. [Architecture Visualization](#-architecture-visualization)
9. [Testing](#-testing)
10. [Development](#-development)

---

## ğŸ¯ Overview

This project implements a production-ready **Model Context Protocol (MCP) server** for Hong Kong's MTR (Mass Transit Railway) system, integrated with **LangGraph agents** and **AWS Bedrock Nova Lite** for natural language interactions.

### What's Included

- âœ… **Full MCP Server** with Tools, Resources, and Prompts
- âœ… **LangGraph Agent** with conversation memory
- âœ… **Natural Language Processing** for 80+ MTR stations
- âœ… **Dual Tool Interface** (human-friendly + machine-readable)
- âœ… **Real-time MTR Data** from Hong Kong government API
- âœ… **LangSmith Integration** for observability
- âœ… **Complete Test Suite** with 6 test files

### Technologies

- **MCP Server**: FastMCP (Python)
- **LLM Framework**: LangGraph + LangChain
- **AI Model**: AWS Bedrock Nova Lite
- **Transport**: Server-Sent Events (SSE)
- **Memory**: MemorySaver (persistent conversations)

---

## ğŸš€ Quick Start

### 1. Installation

```powershell
# Clone or navigate to project directory
cd C:\Users\user\Documents\proj01_chatbot_edu\week08_MCP\mtr-mcp-example

# Activate virtual environment
.\.venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt
```

### 2. Environment Setup

Create `.env` file:

```bash
# AWS Bedrock Credentials
AWS_ACCESS_KEY_ID=your-aws-key
AWS_SECRET_ACCESS_KEY=your-aws-secret
AWS_REGION=us-east-1
BEDROCK_MODEL=amazon.nova-lite-v1:0

# MCP Server
MCP_SERVER_URL=http://localhost:8000/sse

# LangSmith (Optional - for observability)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your-langsmith-api-key
LANGCHAIN_PROJECT=mtr-demo
```

### 3. Start MCP Server

```powershell
python mcp_server.py
```

Expected output:
```
============================================================
ğŸš€ Starting MCP Server
============================================================
ğŸ“¡ SSE Endpoint: http://127.0.0.1:8000/sse
ğŸ” MCP Inspector: Use http://127.0.0.1:8000/sse
âš ï¸  Note: http://127.0.0.1:8000 (without /sse) will give 404
============================================================
INFO:     Started server process [71940]
INFO:     Uvicorn running on http://127.0.0.1:8000
```

### 4. Run LangGraph Demo

In a new terminal:

```powershell
# Demo with conversation history
python langgraph_demo_with_history.py

# Demo with full MCP features + memory
python langgraph_demo_full_mcp.py
```

---

## ğŸ“˜ MCP Protocol Understanding

### What is MCP?

**Model Context Protocol (MCP)** is an open protocol that standardizes how AI applications connect to external data sources and tools. It enables LLMs to securely interact with APIs, databases, and services through a unified interface.

### Core Concepts

MCP defines three types of features that servers can expose:

#### 1. **Tools** (Model-Controlled)

Functions that your LLM can actively call and decides when to use them based on user requests.

| Feature | Who Controls | Example |
|---------|--------------|---------|
| **Tools** | AI Model | Search flights, Send messages, Create calendar events |

**Protocol Operations:**
- `tools/list` - Discover available tools
- `tools/call` - Execute a specific tool

**Example in MTR Server:**
```python
@mcp.tool()
def get_next_train_schedule(line: str, sta: str, lang: str = "EN") -> str:
    """Get MTR train schedule (human-friendly)"""
    # Returns formatted text with emojis
```

**User asks:** "When is the next train?"  
**AI decides:** Call `get_next_train_schedule` tool  
**Result:** Real-time train data

#### 2. **Resources** (Application-Controlled)

Passive data sources that provide read-only access to information for context.

| Feature | Who Controls | Example |
|---------|--------------|---------|
| **Resources** | Application | Retrieve documents, Access knowledge bases, Read calendars |

**Protocol Operations:**
- `resources/list` - List available resources
- `resources/read` - Retrieve resource contents

**Example in MTR Server:**
```python
@mcp.resource("mtr://stations/list")
def get_station_list() -> str:
    """Complete list of all MTR stations with codes"""
    # Returns markdown formatted station reference
```

**Usage Flow:**
1. Application reads `mtr://stations/list`
2. Provides station context to AI
3. AI uses context for better responses

#### 3. **Prompts** (User-Controlled)

Pre-built instruction templates that users explicitly invoke for common tasks.

| Feature | Who Controls | Example |
|---------|--------------|---------|
| **Prompts** | User | Plan a vacation, Summarize meetings, Draft an email |

**Protocol Operations:**
- `prompts/list` - Discover available prompts
- `prompts/get` - Retrieve prompt details

**Example in MTR Server:**
```python
@mcp.prompt()
def plan_mtr_journey(origin: str, destination: str) -> str:
    """Prompt: Plan MTR journey between two stations"""
    return f"""Help me plan an MTR journey from {origin} to {destination}...
    Please:
    1. Use the mtr://lines/map resource to find the route
    2. Check next trains using get_next_train_schedule
    3. Provide step-by-step directions"""
```

**User Experience:**
- User selects "Plan MTR Journey" prompt
- Fills parameters: Origin="TKO", Destination="Central"
- AI receives complete instructions
- AI uses Resources + Tools to complete task

### How Features Work Together

**Complete Journey Planning Example:**

```
1. USER invokes "plan_mtr_journey" prompt
   â””â”€> Parameters: origin="TKO", destination="Central"

2. PROMPT provides instructions
   â””â”€> "Use mtr://lines/map resource"
   â””â”€> "Check trains with get_next_train_schedule"

3. APPLICATION retrieves resources
   â””â”€> Reads mtr://lines/map
   â””â”€> Context: TKO is on TKL, Central on ISL/TWL

4. AI MODEL uses tools
   â””â”€> Calls get_next_train_schedule(line="TKL", sta="TKO")
   â””â”€> Gets: "Next train in 2 minutes"

5. AI responds with complete journey plan
```

---

## âœ¨ Server Features

### MCP Features Implemented

Our MTR server implements the **complete MCP specification**:

| Feature Type | Count | Examples |
|--------------|-------|----------|
| **Tools** | 2 | `get_next_train_schedule`, `get_next_train_structured` |
| **Resources** | 2 | `mtr://stations/list`, `mtr://lines/map` |
| **Prompts** | 3 | `check_next_train`, `plan_mtr_journey`, `compare_stations` |

### Tool 1: `get_next_train_schedule` (Human-Friendly)

**Purpose:** Display train schedules in readable format for end users

**Input:**
```json
{
  "line": "Airport Express",        // or "AEL"
  "sta": "Hong Kong",                // or "HOK"
  "lang": "EN"                       // or "TC" (optional)
}
```

**Output Example:**
```
ğŸ“ Resolved line: 'Airport Express' â†’ 'AEL'
ğŸ“ Resolved station: 'Hong Kong' â†’ 'HOK'

ğŸš‡ MTR Train Schedule for AEL-HOK
ğŸ• Current Time: 2025-10-21 11:27:12
============================================================

â„¹ï¸  Direction Guide:
   ğŸ”¼ UPBOUND = Trains toward outer/peripheral stations
   ğŸ”½ DOWNBOUND = Trains toward central/city stations

ğŸ”¼ UPBOUND Trains:
------------------------------------------------------------
  1. ğŸš† Platform 1 â†’ AWE - 7 minutes (arrives 11:34:00)
  2. ğŸš† Platform 1 â†’ AWE - 17 minutes (arrives 11:44:00)

ğŸ”½ DOWNBOUND Trains: No trains scheduled

============================================================
âœ… Status: Normal operation
```

**Features:**
- âœ… Resolution tracking (shows name â†’ code conversions)
- âœ… Direction guide included
- âœ… Platform numbers
- âœ… Countdown in minutes
- âœ… Exact arrival times
- âœ… Service status

### Tool 2: `get_next_train_structured` (Machine-Readable)

**Purpose:** Provide structured JSON for programmatic agents

**Input:**
```json
{
  "line": "TKL",
  "sta": "Tseung Kwan O",
  "lang": "EN"
}
```

**Output Schema:**
```json
{
  "resolved_line": "TKL",
  "resolved_station": "TKO",
  "timestamp": "2025-10-21 11:27:12",
  "up": [
    {
      "dest": "LHP",
      "ttnt": "0",
      "plat": "1",
      "time": "2025-10-21 11:27:12"
    }
  ],
  "down": [
    {
      "dest": "NOP",
      "ttnt": "1",
      "plat": "2",
      "time": "2025-10-21 11:28:12"
    }
  ],
  "error": null,
  "suggestions": []
}
```

**Agent Usage Pattern:**
```python
# Get structured data
data = await session.call_tool(
    "get_next_train_structured",
    arguments={"line": "TKL", "sta": "TKO"}
)
payload = json.loads(data.content[0].text)

# Extract next train
if payload["up"]:
    next_train = payload["up"][0]
    if int(next_train["ttnt"]) < 3:
        print(f"Hurry! Train leaving in {next_train['ttnt']} min!")
```

### Natural Language Support

**80+ Stations with Fuzzy Matching**

- âœ… Full station names: `"Tseung Kwan O"` â†’ `"TKO"`
- âœ… Line names: `"Airport Express"` â†’ `"AEL"`
- âœ… Station codes: `"TKO"`, `"HOK"`, `"ADM"`
- âœ… Case-insensitive: `"hong kong"` works
- âœ… Fuzzy matching: `"Tseng Kwan O"` (typo) â†’ `"TKO"`

**All 10 MTR Lines Supported:**

| Line Code | Name | Stations | Example Stations |
|-----------|------|----------|------------------|
| **TKL** | Tseung Kwan O | 8 | TKO, LHP, POA, NOP |
| **AEL** | Airport Express | 5 | HOK, KOW, AIR, AWE |
| **ISL** | Island Line | 17 | KET, ADM, CEN, CHW |
| **TCL** | Tung Chung Line | 8 | HOK, OLY, TSY, TUC |
| **TML** | Tuen Ma Line | 27 | WKS, DIH, HOM, TUM |
| **EAL** | East Rail Line | 16 | ADM, UNI, SHS, LMC |
| **SIL** | South Island Line | 5 | ADM, OCP, SOH |
| **TWL** | Tsuen Wan Line | 16 | TST, MOK, LAK, TSW |
| **KTL** | Kwun Tong Line | 17 | WHA, YMT, DIH, TIK |
| **DRL** | Disneyland | 2 | SUN, DIS |

---

## ğŸ¤– LangGraph Integration

### Two Demo Versions

#### 1. `langgraph_demo_with_history.py`

**Focus:** Demonstrates conversation memory and multi-turn context

**Features:**
- âœ… MemorySaver for persistent conversations
- âœ… Thread-based conversation tracking
- âœ… Context references ("that station", "the same line")
- âœ… 1 MCP tool integration
- âœ… 4-turn conversation demo

**Use Case:** Building chatbots with memory

#### 2. `langgraph_demo_full_mcp.py`

**Focus:** Showcases complete MCP protocol + memory

**Features:**
- âœ… All 3 MCP feature types (Tools, Resources, Prompts)
- âœ… 2 tools (human + machine)
- âœ… 2 resources (station list + network map)
- âœ… 3 prompts (check, plan, compare)
- âœ… MemorySaver for conversation history
- âœ… 5-turn conversation demo with context awareness

**Use Case:** Learning MCP + building advanced agents

### Agent Architecture

```
User Query (Natural Language)
    â†“
System Prompt Injected (MTR context)
    â†“
Agent (Nova Lite) + System Context
    â†“
Decision: Need to call tool?
    â”œâ”€ YES â†’ Call MCP Tool
    â”‚         â†“
    â”‚      Tool Execution (MTR API)
    â”‚         â†“
    â”‚      Return to Agent with results
    â”‚         â†“
    â”‚      Format Response
    â””â”€ NO â†’ Generate final response
    â†“
User-Friendly Answer
    â†“
Save to Memory (for next turn)
```

### Conversation Flow with Memory

**Example Multi-turn Interaction:**

```python
# Turn 1
User: "When is the next train at Tseung Kwan O?"
Agent: [Calls tool] "Next train in 3 minutes to LOHAS Park"
Memory: Saves "Tseung Kwan O" context

# Turn 2 (references previous)
User: "What about the other direction?"
Agent: [Uses memory to know "Tseung Kwan O"]
       [Calls tool with opposite direction]
       "Next train in 5 minutes to North Point"

# Turn 3
User: "Compare it with Hong Kong station"
Agent: [Remembers TKO from Turn 1]
       [Calls tool for HOK]
       [Compares both results]
```

---

## ğŸ“ System Prompt Guide

### What Was Enhanced

The LangGraph demos include a **comprehensive system prompt** that transforms the agent from a generic AI into a specialized MTR assistant.

### System Prompt Components

#### 1. **Role Definition**
```
You are a helpful Hong Kong MTR train assistant with access to:
- Real-time train schedules through the MTR API
- Complete station and line information
- Conversation memory for context
```

#### 2. **Tool Usage Instructions**
```
When using tools, provide:
1. line: MTR line code (TKL, AEL, TCL, etc.)
2. sta: Station code (TKO, HOK, CEN, etc.)
3. lang: EN for English or TC for Traditional Chinese
```

#### 3. **Complete Station Reference**

Lists all 10 MTR lines with station codes:

```
Tseung Kwan O Line (TKL): TKO, LHP, HAH, POA, YAT, TIK, NOP, QUB
Airport Express (AEL): HOK, KOW, TSY, AIR, AWE
Island Line (ISL): KET, ADM, CEN, CHW, TIN, CAB, NOP, QUB, ...
```

#### 4. **Response Guidelines**
```
When you receive train data:
- Summarize key information clearly
- Mention minutes until arrival
- Include destination and platform number
- Alert users to service delays
- Be conversational and helpful
- Use context from previous messages
```

#### 5. **Memory Instructions**
```
Remember context from previous messages:
- When users refer to "that station"
- When asked about "the same line"
- When comparing with "the first station I asked about"
```

### Impact Comparison

**Without System Prompt:**
- âŒ Agent might hallucinate station codes
- âŒ Unclear response format
- âŒ No MTR domain knowledge
- âŒ Can't handle natural language queries

**With System Prompt:**
- âœ… Understands MTR system structure
- âœ… Knows all valid line/station codes
- âœ… Consistent, helpful responses
- âœ… Handles natural language: "Hong Kong station on Airport Express"
- âœ… Uses conversation history effectively

### Example Interaction

**User Query:**
```
"I'm at Hong Kong station. When does the next Airport Express train arrive?"
```

**Agent Processing (guided by system prompt):**
1. Recognizes "Hong Kong station" â†’ HOK
2. Recognizes "Airport Express" â†’ AEL
3. Calls: `mtr_train_schedule(line="AEL", sta="HOK", lang="EN")`
4. Receives data
5. Formats response following prompt guidelines

**Agent Response:**
```
The next Airport Express train at Hong Kong station will arrive in 3 minutes.
- Destination: Airport (AIR)
- Arrival Time: 15:23
- Platform: 1

The train after that arrives in 13 minutes.
```

---

## ğŸ“Š LangSmith Observability

### What is LangSmith?

**LangSmith** is a platform for building production-grade LLM applications. It enables you to **debug, test, evaluate, and monitor** AI applications built on any LLM framework.

### Three Core Pillars

#### 1. ğŸ” **Observability** (Tracing & Monitoring)

Track every step of your LLM application:

- **Tracing**: Every LLM call, tool invocation, retrieval
- **Dashboards**: RPS, error rates, costs
- **Alerts**: Get notified of issues
- **Production Monitoring**: Real-world usage patterns

**Why it matters:**
> LLMs are non-deterministic, making them tricky to debug. LangSmith provides LLM-native observability.

#### 2. âœ… **Evaluations** (Testing & Validation)

Build and test with quality datasets:

- **Dataset Creation**: Build test sets from production
- **Automated Evaluators**: Correctness, hallucination detection
- **Custom Evaluators**: Write your own metrics
- **Human Feedback**: Annotation queues
- **A/B Testing**: Compare approaches

#### 3. ğŸ“ **Prompt Engineering** (Iteration & Versioning)

Manage prompts like code:

- **Prompt Hub**: Centralized storage
- **Playground**: Interactive testing
- **Version Control**: Automatic tracking
- **Collaboration**: Share with team
- **Programmatic Access**: Use via API

### Integration with This Project

**Enable LangSmith in 3 lines:**

```python
import os
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "your-api-key"

# That's it! All runs are now traced
```

**What You See:**

```
ğŸ“ Run: "When is the next train?"
â”œâ”€ ğŸ¤– Agent Node (Nova Lite)
â”‚  â”œâ”€ Input: HumanMessage("When is the next train?")
â”‚  â”œâ”€ LLM Call: amazon.nova-lite-v1:0
â”‚  â”‚  â”œâ”€ Tokens: 150 input, 80 output
â”‚  â”‚  â”œâ”€ Cost: $0.0002
â”‚  â”‚  â””â”€ Latency: 1.2s
â”‚  â””â”€ Output: ToolCall(get_train_schedule, {...})
â”‚
â”œâ”€ ğŸ”§ Tools Node (MCP Call)
â”‚  â”œâ”€ Tool: get_train_schedule
â”‚  â”œâ”€ Result: "Next train in 3 minutes..."
â”‚  â””â”€ Latency: 0.5s
â”‚
â””â”€ ğŸ¤– Agent Node (Final Response)
   â””â”€ Total Time: 2.1s
```

**Insights:**
- âœ… What happened (full trace)
- âœ… Why it happened (LLM reasoning)
- âœ… How long it took (per-step latency)
- âœ… How much it cost (token usage)
- âœ… What went wrong (errors)

### Educational Value

**For Teaching:**
- Students see inside the "black box"
- Visual traces show agent decision-making
- Understand cost/latency trade-offs
- Learn debugging techniques

**Before LangSmith:**
```
Teacher: "The agent calls the MCP server."
Student: "How do I know it actually did that?"
Teacher: "Trust me." ğŸ˜…
```

**With LangSmith:**
```
Teacher: "Let's look at the trace."
Student: "Oh! I can see it called get_train_schedule 
          with line='TKL' and sta='TKO'!"
Student: "This makes so much sense now!" ğŸ“
```

---

## ğŸ¨ Architecture Visualization

### LangGraph Flow Diagram

```mermaid
graph TD;
 __start__([START]):::first
 agent(AGENT<br/>LLM + Router)
 tools(TOOLS<br/>MCP Server)
 __end__([END]):::last
 __start__ --> agent;
 agent -. "end" .-> __end__;
 agent -- "tools" --> tools;
 tools --> agent;
 classDef default fill:#f2f0ff,line-height:1.2
 classDef first fill:#90EE90
 classDef last fill:#FFB6C1
```

### Node Descriptions

#### ğŸ¬ **START**
- Entry point for conversations
- Initializes empty message history
- Routes to AGENT node

#### ğŸ¤– **AGENT** (Core Decision Maker)
- **Model**: AWS Bedrock Nova Lite
- **Responsibilities**:
  - Process user messages
  - Access conversation history
  - Decide: Call tools OR provide final answer
- **System Prompt**: Guides MTR assistant behavior
- **Memory**: Full conversation context

#### ğŸ”§ **TOOLS** (Action Executor)
- **MCP Server Integration**: Real-time MTR API
- **Available Tools**:
  - `get_next_train_schedule` (human-friendly)
  - `get_next_train_structured` (machine-readable)
- **Always loops back to AGENT** for processing

#### ğŸ **END**
- Final response generated
- State saved to memory
- Ready for next message

### Edge Descriptions

**START â†’ AGENT** (Direct)
- Always executed at start

**AGENT â†’ TOOLS** (Conditional)
- When: LLM decides tool call needed
- Condition: `should_continue() == "tools"`

**TOOLS â†’ AGENT** (Loop)
- After tool completion
- Carries `ToolMessage` results

**AGENT â†’ END** (Conditional)
- When: No more tools needed
- Condition: `should_continue() == "end"`

### Memory Architecture

```
Thread ID: "demo-conversation"
â”œâ”€â”€ Message 1: HumanMessage
â”œâ”€â”€ Message 2: AIMessage (with tool_calls)
â”œâ”€â”€ Message 3: ToolMessage (results)
â”œâ”€â”€ Message 4: AIMessage (final response)
â”œâ”€â”€ Message 5: HumanMessage (follow-up)
â””â”€â”€ ... (continues)
```

**Benefits:**
- âœ… Context retention across turns
- âœ… Reference previous queries
- âœ… Compare results
- âœ… No repeated information needed

---

## ğŸ§ª Testing

### Test Suite (6 Files)

| Test File | Purpose | Status |
|-----------|---------|--------|
| `test_01_bedrock.py` | AWS Bedrock connection | âœ… PASSED |
| `test_02_agent.py` | Simple agent with add_messages | âœ… PASSED |
| `test_03_mcp.py` | MCP server connection | âœ… PASSED |
| `test_04_natural_language.py` | Station/line resolution | âœ… PASSED |
| `test_05_complete_features.py` | Full feature test | âœ… PASSED |
| `test_06_decoder_structured.py` | Structured JSON tool | âœ… PASSED |

### Running Tests

```powershell
# Individual tests
python test_01_bedrock.py
python test_02_agent.py
python test_03_mcp.py

# Full demos
python langgraph_demo_with_history.py
python langgraph_demo_full_mcp.py
```

### Latest Test Results

```
âœ… test_06_decoder_structured.py

ğŸ“Š Structured Output Schema:
  â”œâ”€ resolved_line: TKL
  â”œâ”€ resolved_station: TKO
  â”œâ”€ timestamp: 2025-10-21 11:27:12
  â”œâ”€ up: 4 trains
  â”œâ”€ down: 4 trains
  â”œâ”€ error: None
  â””â”€ suggestions: []

ğŸ”¼ First Upbound Train:
  â”œâ”€ dest: LHP
  â”œâ”€ ttnt: 0 minutes (DEPARTING NOW)
  â”œâ”€ plat: 1
  â””â”€ time: 2025-10-21 11:27:12

âœ… All tests PASSED
```

---

## ğŸ”§ Development

### Project Structure

```
mtr-mcp-example/
â”œâ”€â”€ mcp_server.py                      # MCP server with Tools/Resources/Prompts
â”œâ”€â”€ langgraph_demo_with_history.py     # LangGraph + Memory demo
â”œâ”€â”€ langgraph_demo_full_mcp.py         # Full MCP features + Memory demo
â”œâ”€â”€ requirements.txt                   # Dependencies
â”œâ”€â”€ .env                               # Environment variables
â”œâ”€â”€ test_01_bedrock.py                 # AWS Bedrock test
â”œâ”€â”€ test_02_agent.py                   # Basic agent test
â”œâ”€â”€ test_03_mcp.py                     # MCP connection test
â”œâ”€â”€ test_04_natural_language.py        # NL resolution test
â”œâ”€â”€ test_05_complete_features.py       # Complete feature test
â”œâ”€â”€ test_06_decoder_structured.py      # Structured tool test
â”œâ”€â”€ README.md                          # This file (unified documentation)
â””â”€â”€ .venv/                             # Virtual environment
```

### Code Organization (mcp_server.py)

```python
mcp_server.py
â”œâ”€ STATION_NAMES dict (80+ stations)
â”œâ”€ LINE_NAMES dict (10 lines)
â”œâ”€ resolve_station_code() - Name/code conversion
â”œâ”€ resolve_line_code() - Line name/code conversion
â”œâ”€ format_train_schedule() - Human-friendly formatting
â”œâ”€ @mcp.tool() get_next_train_schedule - Human tool
â”œâ”€ @mcp.tool() get_next_train_structured - Machine tool
â”œâ”€ @mcp.resource() mtr://stations/list - Station reference
â”œâ”€ @mcp.resource() mtr://lines/map - Network map
â”œâ”€ @mcp.prompt() check_next_train - Quick check prompt
â”œâ”€ @mcp.prompt() plan_mtr_journey - Journey planning prompt
â”œâ”€ @mcp.prompt() compare_stations - Station comparison prompt
â””â”€ main() - FastMCP SSE server on port 8000
```

### Dependencies

```
# Core
requests==2.31.0        # MTR API calls
mcp==1.18.0             # MCP server framework
httpx-sse==0.4.3        # SSE transport

# LangChain/LangGraph
langchain-aws           # AWS Bedrock integration
langgraph              # Agent framework
langchain-core         # Core components

# Standard library
difflib                # Fuzzy matching
datetime               # Timestamps
json                   # JSON handling
```

### Adding New Stations

```python
# In STATION_NAMES dict
"new station name": "NST",
"nst": "NST",
```

### Adding New Lines

```python
# In LINE_NAMES dict
"new line": "NLN",
"nln": "NLN",
```

### Debugging

```python
# Add print statements
def resolve_station_code(station_input: str) -> str:
    normalized = station_input.lower().strip()
    print(f"DEBUG: Resolving '{station_input}' â†’ '{normalized}'")
    # ... rest of function
```

---

## ğŸ“š Key Learnings

### Why Two Tools?

**Human Tool (`get_next_train_schedule`):**
- End users need explanations
- Visual formatting helps readability
- Emojis improve engagement
- Resolution tracking builds trust

**Machine Tool (`get_next_train_structured`):**
- Agents need structured data for logic
- JSON schema enables validation
- Separate up/down arrays simplify parsing
- Error/suggestions enable retry logic

### Why Fuzzy Matching?

- Users make typos ("Tseng" vs "Tseung")
- Mobile autocorrect issues
- Different romanizations
- Accessibility (speech-to-text errors)
- Better user experience (80% similarity threshold)

### Why Both Names AND Codes?

- **Codes** (TKO, HOK): Official MTR identifiers, API requirements
- **Names** ("Tseung Kwan O"): Natural language UX
- **Resolution**: Best of both worlds - natural input, structured API calls

### Why Direction Guide?

User research showed:
- "Upbound" is confusing without context
- Direction varies by line (not universal "north/south")
- First-time MTR users need explanation
- Reduces follow-up questions

### Why Complete System Prompt?

Transforms generic AI into specialized assistant:
- Domain knowledge embedded
- Tool usage guidance
- Response consistency
- Natural language understanding
- Memory awareness

---

## ğŸ¯ Next Steps

### Optional Enhancements

#### 1. **Bilingual Support**
- [ ] Add simultaneous English + Traditional Chinese
- [ ] Station names in both languages
- [ ] Localized error messages

#### 2. **Caching**
- [ ] Cache API responses (5-second TTL)
- [ ] Reduce load on government API
- [ ] Faster response times

#### 3. **Advanced Features**
- [ ] Station proximity search ("nearest station to...")
- [ ] Fare calculation between stations
- [ ] Line status/incidents from MTR feed
- [ ] Service disruption alerts

#### 4. **Documentation**
- [ ] Mermaid diagrams for architecture
- [ ] Postman collection for API testing
- [ ] Video walkthrough
- [ ] Integration guides for other frameworks

#### 5. **Testing**
- [ ] Unit tests for resolvers
- [ ] Integration tests for MCP
- [ ] Load testing for server
- [ ] Mock API responses for offline testing

---

## ğŸ“– Further Reading

### Official Documentation

- **MCP Specification**: https://spec.modelcontextprotocol.io/
- **LangChain**: https://python.langchain.com/
- **LangGraph**: https://langchain-ai.github.io/langgraph/
- **LangSmith**: https://docs.smith.langchain.com/
- **AWS Bedrock**: https://docs.aws.amazon.com/bedrock/

### Project-Specific

All documentation is now consolidated in this README:
- ~~whatismcp.md~~ â†’ See [MCP Protocol Understanding](#-mcp-protocol-understanding)
- ~~MCP_FEATURES.md~~ â†’ See [Server Features](#-server-features)
- ~~MCP_SERVER_SUMMARY.md~~ â†’ See [Overview](#-overview)
- ~~SYSTEM_PROMPT_GUIDE.md~~ â†’ See [System Prompt Guide](#-system-prompt-guide)
- ~~LANGSMITH_OVERVIEW.md~~ â†’ See [LangSmith Observability](#-langsmith-observability)
- ~~graph_mermaid.md~~ â†’ See [Architecture Visualization](#-architecture-visualization)

---

## ğŸ‰ Summary

This project demonstrates a **complete, production-ready MCP server** integrated with **LangGraph agents** for natural language interactions with Hong Kong's MTR system.

### What Makes It Special

âœ… **Full MCP Compliance**: Tools, Resources, Prompts  
âœ… **Conversation Memory**: Multi-turn context awareness  
âœ… **Natural Language**: 80+ stations with fuzzy matching  
âœ… **Dual Interfaces**: Human-friendly + machine-readable  
âœ… **Real-time Data**: Live MTR schedules from HK gov API  
âœ… **Observability**: LangSmith integration  
âœ… **Educational**: Complete documentation and tests  
âœ… **Production-Ready**: Error handling, logging, validation  

### Technologies Demonstrated

- Model Context Protocol (MCP)
- LangGraph agentic workflows
- AWS Bedrock Nova Lite
- LangChain framework
- FastMCP server
- Server-Sent Events (SSE)
- MemorySaver for persistence
- LangSmith observability

### Perfect For

- ğŸ“ Learning MCP and LangGraph
- ğŸ—ï¸ Building production LLM apps
- ğŸ‘¥ Teaching AI agent development
- ğŸ”§ Prototyping conversational AI
- ğŸ“Š Understanding observability

---

**Last Updated:** October 21, 2025  
**Version:** 3.0  
**License:** MIT (if applicable)  
**Maintainer:** Your Name/Team

---

*All previous markdown files have been consolidated into this comprehensive README for easier navigation and maintenance.*
