{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Function Calling Tutorial for Beginners\n",
    "\n",
    "Welcome to this beginner-friendly tutorial on **Function Calling** with **Azure OpenAI**! Function Calling allows you to connect large language models (LLMs) like GPT models to external tools, APIs, or functions. The model can decide when to call a function and provide the necessary arguments based on the user's query.\n",
    "\n",
    "This tutorial uses a Jupyter Notebook (`.ipynb`) format, so you can run the code cells interactively. We'll cover:\n",
    "\n",
    "1. **Setup**: Prerequisites and environment configuration.\n",
    "2. **Basics**: Defining functions and making your first call.\n",
    "3. **Examples**: Real-world scenarios like weather lookup or math calculations.\n",
    "4. **Best Practices**: Tips for production use.\n",
    "\n",
    "**Note**: This tutorial assumes basic Python knowledge. We'll use the `openai` Python library to interact with Azure OpenAI.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- An active **Azure subscription**.\n",
    "- An **Azure OpenAI resource** deployed with a GPT model (e.g., `gpt-4o` or `gpt-35-turbo`).\n",
    "- Your **API key**, **endpoint**, and **deployment name** from the Azure portal.\n",
    "- Python 3.8+ installed.\n",
    "\n",
    "If you haven't set up Azure OpenAI yet:\n",
    "1. Go to the [Azure Portal](https://portal.azure.com).\n",
    "2. Create a new OpenAI resource.\n",
    "3. Deploy a model under \"Model deployments\".\n",
    "4. Note down your endpoint (e.g., `https://your-resource.openai.azure.com/`), API key, and deployment name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, install the required package and set up your environment variables.\n",
    "\n",
    "**Run the cell below to install the OpenAI library.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, import the library and configure your Azure OpenAI client. **Replace the placeholders with your actual values**.\n",
    "\n",
    "For security, use environment variables in production (e.g., via `os.getenv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import os\n",
    "\n",
    "# Replace with your values\n",
    "AZURE_OPENAI_API_KEY = \"your-api-key-here\"\n",
    "AZURE_OPENAI_ENDPOINT = \"https://your-resource.openai.azure.com/\"\n",
    "DEPLOYMENT_NAME = \"your-deployment-name\"  # e.g., gpt-4o\n",
    "\n",
    "# Initialize the client\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2024-02-15-preview\",  # Use a recent API version supporting function calling\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "print(\"Client initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basics of Function Calling\n",
    "\n",
    "Function Calling works in three steps:\n",
    "\n",
    "1. **Define functions**: Describe what the function does, its parameters (in JSON schema format).\n",
    "2. **Send to the model**: Include the functions in your chat completion request.\n",
    "3. **Handle response**: If the model wants to call a function, it returns the function name and arguments. You execute it and feed the result back to the model.\n",
    "\n",
    "Let's define a simple function: `get_current_weather` that takes a location and unit (e.g., Celsius or Fahrenheit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The unit to use\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make a chat completion request. The model will decide if it needs to call the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=DEPLOYMENT_NAME,\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\"  # Let the model decide\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message\n",
    "print(response_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model calls a function, the response will have `function_call` populated. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response_message.function_call:\n",
    "    print(\"Function called:\", response_message.function_call.name)\n",
    "    print(\"Arguments:\", response_message.function_call.arguments)\n",
    "else:\n",
    "    print(\"No function call needed.\")\n",
    "    print(\"Content:\", response_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The model likely called `get_current_weather` with arguments like `{\"location\": \"Boston, MA\"}`.\n",
    "\n",
    "In a real app, you'd now **execute the function** (e.g., query a weather API) and append the result as a `function` role message back to the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock function execution (in reality, call an actual API)\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    # Simulated response\n",
    "    if \"boston\" in location.lower():\n",
    "        return {\n",
    "            \"temperature\": 72,\n",
    "            \"unit\": unit,\n",
    "            \"description\": \"Sunny\"\n",
    "        }\n",
    "    return {\"error\": \"Location not supported\"}\n",
    "\n",
    "# Parse arguments (JSON string to dict)\n",
    "import json\n",
    "function_args = json.loads(response_message.function_call.arguments)\n",
    "function_response = get_current_weather(**function_args)\n",
    "\n",
    "# Add to messages\n",
    "messages.append(response_message)  # Add the assistant's function call message\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": response_message.function_call.name,\n",
    "        \"content\": json.dumps(function_response)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Get final response from model\n",
    "second_response = client.chat.completions.create(\n",
    "    model=DEPLOYMENT_NAME,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model now uses the function result to generate a natural response, e.g., \"It's sunny in Boston with 72°F!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examples\n",
    "\n",
    "### Example 1: Math Calculator\n",
    "\n",
    "Let's add a calculator function for arithmetic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator_function = {\n",
    "    \"name\": \"calculator\",\n",
    "    \"description\": \"Perform basic math calculations\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"expression\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The math expression, e.g., '2 + 2 * 3'\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"expression\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "all_functions = [functions[0], calculator_function]  # Combine with weather function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset messages\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 15 * 4 + 7?\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=DEPLOYMENT_NAME,\n",
    "    messages=messages,\n",
    "    functions=all_functions,\n",
    "    function_call=\"auto\"\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response_message.function_call:\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    # Mock calculator (use eval for simplicity; use safer parsers in production)\n",
    "    try:\n",
    "        result = eval(function_args[\"expression\"])\n",
    "        function_response = {\"result\": result}\n",
    "    except:\n",
    "        function_response = {\"error\": \"Invalid expression\"}\n",
    "    \n",
    "    messages.append(response_message)\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": response_message.function_call.name,\n",
    "            \"content\": json.dumps(function_response)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    final_response = client.chat.completions.create(\n",
    "        model=DEPLOYMENT_NAME,\n",
    "        messages=messages\n",
    "    )\n",
    "    print(final_response.choices[0].message.content)\n",
    "else:\n",
    "    print(response_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Multiple Functions\n",
    "\n",
    "The model can choose from multiple functions. Try querying: \"Calculate 10 + 5 and tell me the weather in New York.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Calculate 10 + 5 and tell me the weather in New York.\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=DEPLOYMENT_NAME,\n",
    "    messages=messages,\n",
    "    functions=all_functions,\n",
    "    function_call=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"Initial response:\", response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiple calls, you may need to loop: check for function calls, execute, append, and repeat until no more calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Best Practices\n",
    "\n",
    "- **Security**: Validate and sanitize function arguments before execution.\n",
    "- **Error Handling**: Always handle cases where the model doesn't call a function or provides invalid args.\n",
    "- **Descriptions**: Write clear function descriptions and parameter schemas—the model relies on these.\n",
    "- **Rate Limits**: Respect Azure OpenAI quotas.\n",
    "- **Production**: Use structured outputs (newer feature) for more reliable JSON parsing.\n",
    "- **Testing**: Start with `function_call={\"name\": \"your_function\"}` to force a call for testing.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore [Azure OpenAI docs](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling).\n",
    "- Integrate with real APIs (e.g., weather via OpenWeatherMap).\n",
    "- Try parallel function calling for efficiency.\n",
    "\n",
    "Thanks for following along! Questions? Experiment with the code cells."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}