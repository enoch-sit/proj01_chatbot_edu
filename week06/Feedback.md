### Bonus Points for Feedback as "Customers"

As per the course rubric, groups can earn up to 10% bonus points for providing constructive feedback to another group's chatbot project, acting as "customers" to simulate stakeholder involvement in Agile/Scrum (e.g., during product backlog refinement or sprint reviews). The bonus is split into 5% for initial feedback at the project start (e.g., feature requests, survey) and 5% for ongoing feedback after the first MVP (e.g., A/B testing, bug reports, surveys, legal considerations). Points are awarded based on quality: full credit for detailed, actionable, evidence-based input; partial for basic efforts; none for superficial or missing feedback. Submit via a shared platform (e.g., GitHub issues or Google Form) for review.

### Feedback Template for Chatbot Application

Use this template to provide feedback. It's structured in phases to align with project stages, with rating scales (1-5: 1 = Poor, 5 = Excellent) and open-ended questions. As a "customer," focus on user perspective—test the chatbot, reference specific examples, and tie feedback to organizational context (e.g., healthcare, education, finance). Complete after interacting with the other group's demo or prototype.

#### Feedback Provider Details
- Your Group Name/ID:  
- Reviewed Group Name/ID:  
- Date of Feedback:  
- Phase (Beginning or After First MVP):  

#### At the Beginning (5% Bonus Eligibility)

1. Customer Requests for Features  
   - List 2-3 specific feature requests based on the organizational context (e.g., "Add voice input for accessibility; integrate calendar API for real-time booking"). Explain the value (e.g., "This would improve user satisfaction by reducing friction").

2. Fill in Survey (If Provided)  
   - If the group provides an initial survey, complete it here or attach responses. Rate overall initial concept (1-5):  
   - Comments: Strengths/weaknesses in early planning (e.g., backlog alignment via user stories)?

#### After the First MVP (5% Bonus Eligibility)

1. Performs A/B Testing for Other Groups (If Provided)  
   - If A/B variants are available, test and compare (e.g., "Version A (text-only) vs. Version B (with images): B had faster response times but lower accuracy on complex queries"). Rate effectiveness (1-5):  
   - Comments: Which variant better meets user needs? Suggestions for refinement.

2. Report Bugs (If Provided)  
   - List any bugs encountered (e.g., "Chatbot crashes on invalid input; error message: 'Undefined variable'"). Include steps to reproduce and screenshots if possible. Rate bug severity (1-5):  
   - Comments: Impact on user experience? Recommendations for fixes.

3. Filling in Survey (If Provided)  
   - If a post-MVP survey is provided, complete it here or attach. Rate MVP performance (1-5):  
   - Comments: How well does it align with initial features/problems? Custom metrics (e.g., task completion rate from your tests).

4. Raising Legal Considerations (If Provided)  
   - Highlight any legal/ethical issues (e.g., "Privacy concern: Chatbot stores user data without consent prompt—suggest GDPR-compliant opt-in"). Rate handling (1-5):  
   - Comments: Risks (e.g., biases in responses) and suggestions (e.g., add disclaimers or audits).

#### Overall Satisfaction
- Rating (1-5): As a customer, how satisfied are you with the chatbot overall?  
- Comments: Does it deliver value in the organizational context? Would you recommend it? Why/why not? (Reference tests or demos.)

#### Comment on User Interface (UI) and Experience
- Rating (1-5): How intuitive and seamless is the UI/experience?  
- Comments: Strengths (e.g., responsive design, visual flows)? Weaknesses (e.g., navigation issues)? Suggestions (e.g., "Add multilingual support for broader accessibility").

This template promotes iterative feedback, tying into Agile principles like customer collaboration and continuous improvement. Groups can use received feedback for backlog refinement or sprint closures. Completion time: 20-30 minutes per phase.